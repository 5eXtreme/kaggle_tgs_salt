# Pytorch RetinaNet

Pytorch implementation of [RetinaNet](https://arxiv.org/pdf/1708.02002.pdf).

![rick morty](imgs/predicted_rick_morty.png)

## Usage

Can be trained on any dataset that conforms to the [PascalVOC](http://host.robots.ox.ac.uk/pascal/VOC/) label format. Essentially, need a folder of images and a folder of xml labels, can be generated by annotating images with [LabelImg](https://github.com/tzutalin/labelImg). Simply point the training code to a folder of images, a folder of xml annotations and pass a unique name for saving the trained model weights. 

```
python train.py --img_folder path/to/images \
                --annots_folder path/to/pascal/annotations \
                --exp_name string_to_create_unique_weights_file \
                --num_class number_of_object_classes
```

Default hyperparameters follow the original paper except that [Adam](https://arxiv.org/pdf/1412.6980.pdf) is used over SGD. 

* **imsize (int)** - the size in pixels that the images are rescaled to before feeding to network. Currenly only takes a single value and rescales images to square.
* **num_class (int)** - number of object classes that have bounding boxes assigned
* **num_scales (int)[1,5]** - how many [FPN](https://arxiv.org/pdf/1506.01497v3.pdf) layers deep to go for training/inference. Higher number allows for better performance on small objects with a slight runtime cost. Recommend setting this to 5 for training then scaling it down if needed for inference.
* **fpn_depth (18 or 50)** - whether to use a 18-layer or 50-layer [ResNet](https://arxiv.org/abs/1512.03385) as the FPN backbone.
* **batch_size (int)** - how large of a batch to use during training
* **epochs (int)** - maximum number of epochs to use during training
* **lr (float)** - learning rate for Adam
* **lr_scale (float)** - how much to scale learning rate on validation performance plateau
* **l2 (float)** - how much weight decay to use in the optimizer, higher values can prevent overfitting
* **lambda_bbox (float)** - how much to scale the bounding box regression in the loss function, higher numbers will bias loss towards bounding box performance rather than class performance
* **gamma (float)** - gamma value for focal loss
* **alpha (float)** - alpha value for focal loss
* **es_patience (int)** - how long to wait in a validation loss plateau before stopping training
* **lr_patience (int)** - how long to wait in a validation loss plateau before rescaling learning rate
* **gpu (int)** - which gpu to use for training, value of 99 will use all in parallel
* **model_name (string)** - what to name the saved model, default 'retinanet'
* **exp_name (string)** - unique name to give the current training run, used for saving unqiue weights 
* **debug** - flag used to turn on more verbose model training

## Installation

Install these.

```
glob2==0.6
matplotlib==2.2.0
numpy==1.14.2
opencv-contrib-python==3.4.1.15
scikit-image==0.13.1
torch==0.4.0
torchsample==0.1.3
torchvision==0.2.1
```

## Coming soon

* **More data augmentations**
* **Less stuff being hardcoded**
* **More backbone networks**
* **Pretrained model on OpenImages**
* **Pretrained model on COCO**
* **Transfer to Caffe2 for inference**
